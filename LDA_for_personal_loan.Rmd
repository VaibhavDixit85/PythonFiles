---
title: "SA1_IA"
author: "Vaibhav Dixit_12110100"
date: "3/26/2022"
output: html_document
---

```{r}
#Q1. Build a Discriminant Analysis Model to predict whether the person is likely to accept the bank’s offer for a personal loan. If necessary, create new variables to improve the model performance

#Loading the data into the database
# From summary we can see that in Experience column we have some negative values converting them into positive values through abs

library("readxl")
setwd("D:/ISB_AMPBA/Term4/ASA/")
my_data <- read_excel("ASA_Assgnment1.xlsx")

summary(my_data)

my_data$Experience <- abs(my_data$Experience)
my_data <- data.frame(my_data)
```
```{r}
#Plotting the density f(n) for different features 
plot(density(my_data$Age))
plot(density(my_data$Experience))
plot(density(my_data$Income))
plot(density(my_data$ZIP.Code))
plot(density(my_data$Family))
plot(density(my_data$CCAvg))
plot(density(my_data$Education))
plot(density(my_data$Mortgage))
plot(density(my_data$Securities.Account))
plot(density(my_data$CD.Account))
plot(density(my_data$Online))
plot(density(my_data$CreditCard))
```
```{r}
## Seeing the above graph we can see that there are categorical variables 
## Family
## Education 
## Securities Account 
## CD Account 
## Online 
## Credit Card
## Whereas for Zip.code we can see high dimensonality which will impact the prediction. Hence we will drop the column Zipcode 
## Also, We will normalize the columns for income and CCavg as they didn't seem normal plus have significant differnece between Mean and Median
my_data$tr_income <- sqrt(my_data$Income)
my_data$tr_ccavg <- sqrt(my_data$CCAvg)

my_data <- my_data[-c(4)]
my_data_flda <- my_data
my_data <- my_data[-c(3)]
my_data <- my_data[-c(4)]

#Plotting the density function for transformed variables

plot(density(my_data$tr_income))
plot(density(my_data$tr_ccavg))
```
```{r}
## Splitting the data into train and test 
train_size <- floor(0.70 * nrow(my_data))
set.seed(213)
train_ind <- sample(seq_len(nrow(my_data)),
size = train_size)
train <- my_data[train_ind,]
test <- my_data[-train_ind,]
```
```{r}
## Fitting LDA model into the data set
library(MASS)
lda.fit1 <- lda(Personal_Loan~.,data=train)
lda.fit1

#Observations are as below
# As per the training dataset 90% of the observations corresponds to one where one didn't get the loan and 10% those which get the loan
# Group means tells us how each that we use differs in each class of our direction
# From the group means we can say that the predictor 
#Income, CC Avg , Education, Mortgage and securities account 
#if have higher mean chances of loan approval are more
# from the coefficients of linear discriminants we can form a decision rule
# Zi = -0.006442Age + 0.009822Experience + 0.159458Family + 0.596965Education + 0.000687Mortgage + (-0.473328)Securities.Account + 2.083070CD.Account + 0.209581Online + (-0.326787)CreditCard + 0.345461tr_income + 0.310630tr_ccavg


```
```{r}
# Based on large Zi value classier will predict that loan should be granted whereas for low loan should not be approved. Threshold can be descided as '0' as per the below plot
par(mar = rep(2, 4))
plot(lda.fit1, type = 'b')

lda.data <- cbind(train, predict(lda.fit1)$x)
library(ggplot2)
ggplot(lda.data, aes(LD1, Age)) + geom_point(aes(color = Personal_Loan))

```
```{r}
my_data1 <- my_data
my_data1$is_mortgage <- ifelse(my_data$Mortgage == 0,"no","yes")

train_size1 <- floor(0.70 * nrow(my_data1))
set.seed(213)
train_ind1 <- sample(seq_len(nrow(my_data1)),
                    size = train_size1)
train1 <- my_data1[train_ind1,]
test1 <- my_data1[-train_ind1,]

library(MASS)
lda.fit2 <- lda(Personal_Loan~.,data=train1)
lda.fit2

#predictiona <- lda.fit2 %>% predict(test1)

#mean(predictiona$class==test1$Personal_Loan)

# On output we can see that accuracy doesn't change much  on creating a new variable is mortgage yes or no
```
```{r}
## Wilk's lambda test
library(dplyr)
my_data <- my_data %>% relocate(Personal_Loan, .before = Age)
my_data <- my_data %>% relocate(tr_income, .before = Mortgage)

X <- cbind(as.matrix(my_data[, 2:12]))
Y <- my_data$Personal_Loan
manova.fit1 <- manova(X ~ Y, my_data)
summary(manova.fit1, test = "Wilks")

## As we can see that Wilks lambda value and P-value is very low hence group means of the variables have significant difference
```
```{r}
#Comments on the variables that are significant

# from the coefficients of LD1 we can say that the #most significant variables is CD.account followed by Education and Securities account 
#whereas Credit card , Income and CCavg have similar significance and 
#Mortgage is least significatnce 
#followed by Age and Experience 
```
```{r}
# Create on confusion matrix and comment on prediction accuracy

print("Confusion Matrix as below")
lda.pred <- predict(lda.fit1, test)
table(lda.pred$class, test$Personal_Loan)
print("Accuracy as below")
mean(lda.pred$class==test$Personal_Loan)

# From the confusion matrix we can say that misclassification is less 
# Accuracy is 93% 
# However, Precision and recall of the model on test data is not that good 
# Precision is 0.41 
# Recall is 0.58
# Whereas specificity is high
```
```{r}
#Q5. The bank would like to address the top 30 persons with an offer for personal loan based on the probability (propensity). Create a table displaying all the details of the “top” 30 persons who are most likely to accept the bank’s offer. Make sure to include the probability of accepting the offer along with all the other details.

library(DiscriMiner)
library(caret)
library(dplyr)

my_data <- my_data %>% relocate(Personal_Loan, .after = tr_ccavg)
da.reg <- linDA(my_data[,1:11], my_data[,12])
da.reg$functions
table(da.reg$classification, my_data$Personal_Loan)

propensity.loan <- exp(da.reg$scores[,2])/(exp(da.reg$scores[,1])+exp(da.reg$scores[,2]))

pros_data <- data.frame(Actual=my_data$Personal_Loan, da.reg$classification, da.reg$scores, propensity.loan=propensity.loan)

predict_lda_full <- lda.fit1 %>% predict(my_data)

lda.data_30_1 <- cbind(my_data_flda,predict_lda_full)

lda.data_final <- cbind(lda.data_30_1,pros_data)

lda.data_final_1 <- lda.data_final[lda.data_final$Personal_Loan == 1,]

top30_lda <- head(lda.data_final_1[order(-lda.data_final_1$propensity.loan),],30)

## Below here is the list of top 30 through LDA who likely to accept the bank offer

top30_lda

write.csv(top30_lda,"D:/ISB_AMPBA/Term4/ASA/top30_lda.csv", row.names = FALSE)


```
